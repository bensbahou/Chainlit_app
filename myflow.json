{"name":"myflow","description":"Language Chainlink Master.","data":{"nodes":[{"width":384,"height":609,"id":"ChatOpenAI-fsS0g","type":"genericNode","position":{"x":100.28920470743174,"y":418.19851752166255},"data":{"type":"ChatOpenAI","node":{"template":{"verbose":{"required":false,"placeholder":"","show":false,"multiline":false,"value":false,"password":false,"name":"verbose","advanced":false,"type":"bool","list":false},"callbacks":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"callbacks","advanced":false,"type":"langchain.callbacks.base.BaseCallbackHandler","list":true},"tags":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"tags","advanced":false,"type":"str","list":true},"client":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"client","advanced":false,"type":"Any","list":false},"model_name":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"gpt-4","password":false,"options":["gpt-3.5-turbo-0613","gpt-3.5-turbo","gpt-3.5-turbo-16k-0613","gpt-3.5-turbo-16k","gpt-4-0613","gpt-4-32k-0613","gpt-4","gpt-4-32k"],"name":"model_name","advanced":false,"type":"str","list":true},"temperature":{"required":false,"placeholder":"","show":true,"multiline":false,"value":0.7,"password":false,"name":"temperature","advanced":false,"type":"float","list":false},"model_kwargs":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"model_kwargs","advanced":true,"type":"code","list":false},"openai_api_key":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"","password":true,"name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"type":"str","list":false},"openai_api_base":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"openai_api_base","display_name":"OpenAI API Base","advanced":false,"type":"str","list":false},"openai_organization":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"openai_organization","display_name":"OpenAI Organization","advanced":false,"type":"str","list":false},"openai_proxy":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"openai_proxy","display_name":"OpenAI Proxy","advanced":false,"type":"str","list":false},"request_timeout":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"request_timeout","advanced":false,"type":"float","list":false},"max_retries":{"required":false,"placeholder":"","show":false,"multiline":false,"value":6,"password":false,"name":"max_retries","advanced":false,"type":"int","list":false},"streaming":{"required":false,"placeholder":"","show":false,"multiline":false,"value":false,"password":false,"name":"streaming","advanced":false,"type":"bool","list":false},"n":{"required":false,"placeholder":"","show":false,"multiline":false,"value":1,"password":false,"name":"n","advanced":false,"type":"int","list":false},"max_tokens":{"required":false,"placeholder":"","show":true,"multiline":false,"password":true,"name":"max_tokens","advanced":false,"type":"int","list":false,"value":""},"_type":"ChatOpenAI"},"description":"Wrapper around OpenAI Chat large language models.","base_classes":["BaseLanguageModel","ChatOpenAI","BaseChatModel","Serializable"],"display_name":"ChatOpenAI"},"id":"ChatOpenAI-fsS0g","value":null},"selected":false,"positionAbsolute":{"x":100.28920470743174,"y":418.19851752166255},"dragging":false},{"width":384,"height":286,"id":"ConversationChain-rrUPA","type":"genericNode","position":{"x":811.6386265810986,"y":635.9874061271191},"data":{"type":"ConversationChain","node":{"template":{"memory":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"memory","advanced":false,"type":"BaseMemory","list":false},"callbacks":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"callbacks","advanced":false,"type":"langchain.callbacks.base.BaseCallbackHandler","list":true},"verbose":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"verbose","advanced":true,"type":"bool","list":false},"tags":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"tags","advanced":false,"type":"str","list":true},"prompt":{"required":false,"placeholder":"","show":false,"multiline":false,"value":{"input_variables":["history","input"],"output_parser":null,"partial_variables":{},"template":"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\n{history}\nHuman: {input}\nAI:","template_format":"f-string","validate_template":true,"_type":"prompt"},"password":false,"name":"prompt","advanced":false,"type":"BasePromptTemplate","list":false},"llm":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"llm","advanced":false,"type":"BaseLanguageModel","list":false},"output_key":{"required":true,"placeholder":"","show":true,"multiline":false,"value":"response","password":false,"name":"output_key","advanced":true,"type":"str","list":false},"output_parser":{"required":false,"placeholder":"","show":false,"multiline":false,"value":{"_type":"default"},"password":false,"name":"output_parser","advanced":false,"type":"BaseLLMOutputParser","list":false},"return_final_only":{"required":false,"placeholder":"","show":false,"multiline":false,"value":true,"password":false,"name":"return_final_only","advanced":false,"type":"bool","list":false},"llm_kwargs":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"llm_kwargs","advanced":false,"type":"code","list":false},"input_key":{"required":true,"placeholder":"","show":true,"multiline":false,"value":"input","password":false,"name":"input_key","advanced":true,"type":"str","list":false},"_type":"ConversationChain"},"description":"Chain to have a conversation and load context from memory.","base_classes":["ConversationChain","Serializable","Chain","LLMChain","function"],"display_name":"ConversationChain"},"id":"ConversationChain-rrUPA","value":null},"selected":false,"positionAbsolute":{"x":811.6386265810986,"y":635.9874061271191}}],"edges":[{"source":"ChatOpenAI-fsS0g","sourceHandle":"ChatOpenAI|ChatOpenAI-fsS0g|BaseLanguageModel|ChatOpenAI|BaseChatModel|Serializable","target":"ConversationChain-rrUPA","targetHandle":"BaseLanguageModel|llm|ConversationChain-rrUPA","style":{"stroke":"#555555"},"className":"","animated":false,"id":"reactflow__edge-ChatOpenAI-fsS0gChatOpenAI|ChatOpenAI-fsS0g|ChatOpenAI|Serializable|BaseChatModel|BaseLanguageModel-ConversationChain-rrUPABaseLanguageModel|llm|ConversationChain-rrUPA","selected":false}],"viewport":{"x":-10.093386424859432,"y":-387.22758355275744,"zoom":0.9986565158978951}},"id":"ad7c94cb-8ad8-46cf-89bf-fc8a7d260e8c","style":null}